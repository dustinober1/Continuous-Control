{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56b4dae",
   "metadata": {},
   "source": [
    "# Demo: Training Progress GIF and Checkpoint Save/Load\n",
    "\n",
    "This short demo shows how to embed the generated `training_progress.gif` and provides a runnable PyTorch example that creates, saves, and loads a small checkpoint. The notebook is self-contained and does not require the Unity environment to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f834b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Import Required Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "print('torch version:', getattr(torch, '__version__', 'unknown'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba231d6e",
   "metadata": {},
   "source": [
    "## Embed training_progress.gif\n",
    "\n",
    "If you have run `python3 generate_plot.py` the GIF will be at `checkpoints/demos/training_progress.gif`. If not present, change the path below to a GIF in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecacb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Display the GIF if present\n",
    "gif_path = Path('checkpoints/demos/training_progress.gif')\n",
    "if gif_path.exists():\n",
    "    display(Image(str(gif_path)))\n",
    "else:\n",
    "    print('GIF not found at', gif_path)\n",
    "    print('Run: python3 generate_plot.py --checkpoints checkpoints --out checkpoints/demos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f823899d",
   "metadata": {},
   "source": [
    "## Minimal PyTorch model and dummy input\n",
    "\n",
    "We define a tiny MLP and create a dummy input for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfc479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyMLP(nn.Module):\n",
    "    def __init__(self, input_dim=8, hidden=16, output_dim=4):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "input_dim = 8\n",
    "model = TinyMLP(input_dim=input_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "dummy_input = torch.randn(1, input_dim)\n",
    "print('Model parameter count:', sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d37baf6",
   "metadata": {},
   "source": [
    "## Create and save a sample checkpoint\n",
    "\n",
    "Run a single forward/backward step to modify weights and save a checkpoint named `checkpoint.pth` in the notebook working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db41b83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Single training step and save checkpoint\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "output = model(dummy_input)\n",
    "loss = output.pow(2).mean()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "ckpt = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': 1\n",
    "}\n",
    "\n",
    "ckpt_path = Path('checkpoint.pth')\n",
    "torch.save(ckpt, str(ckpt_path))\n",
    "print('Saved checkpoint to', ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4d12b6",
   "metadata": {},
   "source": [
    "## Load checkpoint and run inference (runnable example)\n",
    "\n",
    "This cell creates a fresh model, loads the saved checkpoint, and runs inference on the dummy input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e03a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Load the checkpoint and run inference\n",
    "try:\n",
    "    ckpt = torch.load('checkpoint.pth', map_location='cpu')\n",
    "    model2 = TinyMLP(input_dim=input_dim)\n",
    "    model2.load_state_dict(ckpt['model_state_dict'])\n",
    "    model2.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model2(dummy_input)\n",
    "    print('Inference output (tensor):', out)\n",
    "except FileNotFoundError:\n",
    "    print('checkpoint.pth not found. Run the previous cell to create one.')\n",
    "except Exception as e:\n",
    "    print('Error loading or running model:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e457e8",
   "metadata": {},
   "source": [
    "## Capture output summary (JSON)\n",
    "\n",
    "This final cell prints a small JSON summary so outputs are easy to inspect in the VS Code Output pane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a78741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Output summary and execution hint\n",
    "try:\n",
    "    summary = {\n",
    "        'loaded_epoch': int(ckpt.get('epoch', -1)),\n",
    "        'output_shape': list(out.shape)\n",
    "    }\n",
    "    print(json.dumps(summary))\n",
    "except Exception as e:\n",
    "    print('Could not create summary:', e)\n",
    "\n",
    "# Hint: to execute this notebook from a terminal:\n",
    "# jupyter nbconvert --to notebook --execute demo.ipynb --output demo_executed.ipynb"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
